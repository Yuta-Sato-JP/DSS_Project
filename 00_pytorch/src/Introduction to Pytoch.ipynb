{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d57768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.13.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "print(\"torch: {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a11292",
   "metadata": {},
   "source": [
    "### Import a preset dataset \"FashionMNIST\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6757e4",
   "metadata": {},
   "source": [
    "Yuta's comment:\n",
    "It is important to understand the data structure of which PyTorch is going to handle.\n",
    "As a first step, let's use the preset dataset called \"FashionMNIST\". (Fashion image version of MNIST) Please note that we usually need to create our own **torch.utils.data.Dataset** class by ourselves, and eventually **torch.utils.data.DataLoader** with parameter of batch size, sampling method, and so on. More Info [here.](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9877b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c498531f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.FashionMNIST'>\n",
      "<class 'torchvision.datasets.mnist.FashionMNIST'>\n",
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# check the class of each dataset\n",
    "print(type(training_data))\n",
    "print(type(test_data))\n",
    "\n",
    "# check the size of each dataset\n",
    "print(len(training_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b0a464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we see an image, it only shows a tensor, instead of the visualised image itself.\n",
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbfac6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# check the class of a image (it is nested in tuple, where the first component is torch.Tensor and the other is label number.)\n",
    "print(type(training_data[0][0]))\n",
    "\n",
    "# check the size of a image (you can confirm that it is 28*28 black-white image)\n",
    "print(training_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f6a2172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f82f0095550>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's visualise the image\n",
    "plt.imshow(training_data[0][0].squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2343b37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "# the category of this dataset is stored in an attribute \"classes\".\n",
    "print(training_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd5f09a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coat\n"
     ]
    }
   ],
   "source": [
    "# let's see the category of the first image.\n",
    "print(training_data.classes[training_data[0][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47fb6d3",
   "metadata": {},
   "source": [
    "**torch.utils.data.DataLoader** is a class which can deal with **torch.utils.data.Dataset**, so that we can train and validate the model efficiently (we only have to put the number od batch size, then PyTorch will process the data splitting automatically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d95371c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# create data loaders\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a1a3f",
   "metadata": {},
   "source": [
    "Please note that if you want to create your own **torch.utils.data.Dataset**, you need to specify __init__, __len__, and __getitem__. (These are used in a model afterwards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074bee92",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb9e05f",
   "metadata": {},
   "source": [
    "Now it's time to build a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9249ddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training. If you don't use NVIDIA's GPU, CPU will be automatically chosen.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "705ffe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurOwnFirstNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        # inherit the class of nn.Module (this is a convention of pytorch)\n",
    "        super().__init__()\n",
    "        \n",
    "        # flatten is to make a tensor into one single vector (ex. 1*28*28 -> 784)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # build a three-layer neural network with activation of ReLU.\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    # this method \"forward\" will be used when the model excutes forward propagation.\n",
    "    # you can imagine that \"x\" is a single image.\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a46e6bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OurOwnFirstNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# let's create an instance from our class.\n",
    "our_model = OurOwnFirstNetwork().to(device)\n",
    "print(our_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe03bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to specify the loss function of this model, as well as the method of its optimisation.\n",
    "# in this case, we are going to use cross entropy loss with SGD.\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(our_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d69e6e",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca787a",
   "metadata": {},
   "source": [
    "Now let's train the model! To do so, we need to make some new functions out of our class definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a02cc992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_our_model(dataloader, model, loss_fn, optimizer):\n",
    "    \n",
    "    #  the total size of this dataloader (in this case we will inspect the one for training)\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # use the method of \"train\" from our created instance (it is hard to understand because it is from nn.Module)\n",
    "    model.train()\n",
    "    \n",
    "    # for each of batch\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # whether we use CUDA or not\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # If we put \"X\" into our instance, pytorch will process the forward propergation.\n",
    "        pred = model(X)\n",
    "        \n",
    "        # based on the prediction, we need to calculate the loss function\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # now it's time to do back propagation! Firstly, we need to reset the gradient in advance (this happens in every loop).\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # do the back propagation! In this method of \"backward\" from nn.Module, pytorch is calculating the gradient.\n",
    "        loss.backward()\n",
    "        \n",
    "        # based on the calculated gradient for each neuron, we can take a step of optimisation.\n",
    "        optimizer.step()\n",
    "        \n",
    "        # this is for convenience of seeing the progress of training (only showing every 100 batches)\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a76676",
   "metadata": {},
   "source": [
    "As well as the train function, we need to create a function for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ea90cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_our_model(dataloader, model, loss_fn):\n",
    "    \n",
    "    # get the total size of this dataloader (in this case we will inspect the one for testing)\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # the length of dataloader is the number of batches, so we will get it\n",
    "    # the reason why we did'nt do this in the train function is we wanted to see the progress of training using the enumeration.\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    # use the method of eval from our instance (this method comes originally from nn.Module)\n",
    "    model.eval()\n",
    "    \n",
    "    # initialise the loss and correct prediction number as 0\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # disable the gradient calculation, since we won't do back propagation\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            \n",
    "            # use CUDA if available\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # put the \"X\" into our trained model\n",
    "            pred = model(X)\n",
    "            \n",
    "            # pile the loss from each batch\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            # from the logit, we will take argmax to explicitly predict a label for each image.\n",
    "            # it the prediction from argmax is correct, we will add it to \"correct\"\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        \n",
    "        # average out the test loss after all the testing is finished.\n",
    "        test_loss /= num_batches\n",
    "        \n",
    "        # average out the \"correct\" after all the testing is finished.\n",
    "        correct /= size\n",
    "\n",
    "        # show the result\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cd59b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305804  [    0/60000]\n",
      "loss: 2.290419  [ 6400/60000]\n",
      "loss: 2.277578  [12800/60000]\n",
      "loss: 2.274362  [19200/60000]\n",
      "loss: 2.254799  [25600/60000]\n",
      "loss: 2.233813  [32000/60000]\n",
      "loss: 2.232197  [38400/60000]\n",
      "loss: 2.208999  [44800/60000]\n",
      "loss: 2.199719  [51200/60000]\n",
      "loss: 2.179492  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.7%, Avg loss: 2.169364 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.172896  [    0/60000]\n",
      "loss: 2.166924  [ 6400/60000]\n",
      "loss: 2.117221  [12800/60000]\n",
      "loss: 2.139504  [19200/60000]\n",
      "loss: 2.100432  [25600/60000]\n",
      "loss: 2.031985  [32000/60000]\n",
      "loss: 2.060431  [38400/60000]\n",
      "loss: 1.989859  [44800/60000]\n",
      "loss: 1.984090  [51200/60000]\n",
      "loss: 1.932695  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 1.926222 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.943894  [    0/60000]\n",
      "loss: 1.926046  [ 6400/60000]\n",
      "loss: 1.819224  [12800/60000]\n",
      "loss: 1.867050  [19200/60000]\n",
      "loss: 1.771091  [25600/60000]\n",
      "loss: 1.696237  [32000/60000]\n",
      "loss: 1.722495  [38400/60000]\n",
      "loss: 1.625000  [44800/60000]\n",
      "loss: 1.640464  [51200/60000]\n",
      "loss: 1.541238  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 1.560194 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.612693  [    0/60000]\n",
      "loss: 1.585693  [ 6400/60000]\n",
      "loss: 1.441978  [12800/60000]\n",
      "loss: 1.518746  [19200/60000]\n",
      "loss: 1.404372  [25600/60000]\n",
      "loss: 1.373077  [32000/60000]\n",
      "loss: 1.387032  [38400/60000]\n",
      "loss: 1.312925  [44800/60000]\n",
      "loss: 1.342926  [51200/60000]\n",
      "loss: 1.238515  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.272055 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.342825  [    0/60000]\n",
      "loss: 1.327653  [ 6400/60000]\n",
      "loss: 1.165827  [12800/60000]\n",
      "loss: 1.275907  [19200/60000]\n",
      "loss: 1.156582  [25600/60000]\n",
      "loss: 1.159824  [32000/60000]\n",
      "loss: 1.176961  [38400/60000]\n",
      "loss: 1.117437  [44800/60000]\n",
      "loss: 1.151881  [51200/60000]\n",
      "loss: 1.062490  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 1.092379 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# set the number of epoch (how many times we will use the whole training dataset)\n",
    "epochs = 5\n",
    "\n",
    "# for each of the epoch, we will do train & test.\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    \n",
    "    # do the train!\n",
    "    train_our_model(train_dataloader, our_model, loss_fn, optimizer)\n",
    "    \n",
    "    # do the test!\n",
    "    test_our_model(test_dataloader, our_model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a613b839",
   "metadata": {},
   "source": [
    "### Predict image labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc7ec9",
   "metadata": {},
   "source": [
    "Now the model is trained! Let's see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d03c2a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8334f9cb10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_data[0][0].squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8703d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5635,  2.3077, -0.0655,  2.5371,  0.3295, -1.5189,  0.6700, -2.0918,\n",
      "         -1.3135, -1.7355]], grad_fn=<AddmmBackward0>)\n",
      "3\n",
      "Dress\n"
     ]
    }
   ],
   "source": [
    "# get the predicted outcome\n",
    "predicted_outcome = our_model(test_data[0][0])\n",
    "print(predicted_outcome)\n",
    "\n",
    "# get the id\n",
    "predicted_id = int(predicted_outcome.argmax())\n",
    "print(predicted_id)\n",
    "\n",
    "# get the label\n",
    "predicted_label = test_data.classes[predicted_id]\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1668b6a",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b745dd4",
   "metadata": {},
   "source": [
    "When we will use the model with its trained parameters, we can save it as \"pth\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca6d47ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(our_model.state_dict(), \"../data/model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
