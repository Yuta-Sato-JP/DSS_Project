{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d57768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.13.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "print(\"torch: {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3c11d",
   "metadata": {},
   "source": [
    "### Import a preset dataset \"FashionMNIST\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5d82d",
   "metadata": {},
   "source": [
    "Yuta's comment:\n",
    "It is important to understand the data structure of which PyTorch is going to handle.\n",
    "As a first step, let's use the preset dataset called \"FashionMNIST\". (Fashion image version of MNIST) Please note that we usually need to create our own **torch.utils.data.Dataset** class by ourselves, and eventually **torch.utils.data.DataLoader** with parameter of batch size, sampling method, and so on. More Info [here.](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f2be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "863b71e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.FashionMNIST'>\n",
      "<class 'torchvision.datasets.mnist.FashionMNIST'>\n",
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# check the class of each dataset\n",
    "print(type(training_data))\n",
    "print(type(test_data))\n",
    "\n",
    "# check the size of each dataset\n",
    "print(len(training_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11dac36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we see an image, it only shows a tensor, instead of the visualised image itself.\n",
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d917d1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# check the class of a image (it is nested in tuple, where the first component is torch.Tensor and the other is label number.)\n",
    "print(type(training_data[0][0]))\n",
    "\n",
    "# check the size of a image (you can confirm that it is 28*28 black-white image)\n",
    "print(training_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdb34d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8334723450>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's visualise the image\n",
    "plt.imshow(training_data[0][0].squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54ec797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "# the category of this dataset is stored in an attribute \"classes\".\n",
    "print(training_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a005fd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle boot\n"
     ]
    }
   ],
   "source": [
    "# let's see the category of the first image.\n",
    "print(training_data.classes[training_data[0][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac80569",
   "metadata": {},
   "source": [
    "**torch.utils.data.DataLoader** is a class which can deal with **torch.utils.data.Dataset**, so that we can train and validate the model efficiently (we only have to put the number od batch size, then PyTorch will process the data splitting automatically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e10e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# create data loaders\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd4b08",
   "metadata": {},
   "source": [
    "Please note that if you want to create your own **torch.utils.data.Dataset**, you need to specify __init__, __len__, and __getitem__. (These are used in a model afterwards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5bf8d6",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe63bbc",
   "metadata": {},
   "source": [
    "Now it's time to build a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cb61057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training. If you don't use NVIDIA's GPU, CPU will be automatically chosen.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1b865a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurOwnFirstNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        # inherit the class of nn.Module (this is a convention of pytorch)\n",
    "        super().__init__()\n",
    "        \n",
    "        # flatten is to make a tensor into one single vector (ex. 1*28*28 -> 784)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # build a three-layer neural network with activation of ReLU.\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    # this method \"forward\" will be used when the model excutes forward propagation.\n",
    "    # you can imagine that \"x\" is a single image.\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f21f47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OurOwnFirstNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# let's create an instance from our class.\n",
    "our_model = OurOwnFirstNetwork().to(device)\n",
    "print(our_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19cb1ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to specify the loss function of this model, as well as the method of its optimisation.\n",
    "# in this case, we are going to use cross entropy loss with SGD.\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(our_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa31e7",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e428a20",
   "metadata": {},
   "source": [
    "Now let's train the model! To do so, we need to make some new functions out of our class definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c6131ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_our_model(dataloader, model, loss_fn, optimizer):\n",
    "    \n",
    "    #  the total size of this dataloader (in this case we will inspect the one for training)\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # use the method of \"train\" from our created instance (it is hard to understand because it is from nn.Module)\n",
    "    model.train()\n",
    "    \n",
    "    # for each of batch\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # whether we use CUDA or not\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # If we put \"X\" into our instance, pytorch will process the forward propergation.\n",
    "        pred = model(X)\n",
    "        \n",
    "        # based on the prediction, we need to calculate the loss function\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # now it's time to do back propagation! Firstly, we need to reset the gradient in advance (this happens in every loop).\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # do the back propagation! In this method of \"backward\" from nn.Module, pytorch is calculating the gradient.\n",
    "        loss.backward()\n",
    "        \n",
    "        # based on the calculated gradient for each neuron, we can take a step of optimisation.\n",
    "        optimizer.step()\n",
    "        \n",
    "        # this is for convenience of seeing the progress of training (only showing every 100 batches)\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230597cf",
   "metadata": {},
   "source": [
    "As well as the train function, we need to create a function for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c9ef7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_our_model(dataloader, model, loss_fn):\n",
    "    \n",
    "    # get the total size of this dataloader (in this case we will inspect the one for testing)\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # the length of dataloader is the number of batches, so we will get it\n",
    "    # the reason why we did'nt do this in the train function is we wanted to see the progress of training using the enumeration.\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    # use the method of eval from our instance (this method comes originally from nn.Module)\n",
    "    model.eval()\n",
    "    \n",
    "    # initialise the loss and correct prediction number as 0\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # disable the gradient calculation, since we won't do back propagation\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            \n",
    "            # use CUDA if available\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # put the \"X\" into our trained model\n",
    "            pred = model(X)\n",
    "            \n",
    "            # pile the loss from each batch\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            # from the logit, we will take argmax to explicitly predict a label for each image.\n",
    "            # it the prediction from argmax is correct, we will add it to \"correct\"\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        \n",
    "        # average out the test loss after all the testing is finished.\n",
    "        test_loss /= num_batches\n",
    "        \n",
    "        # average out the \"correct\" after all the testing is finished.\n",
    "        correct /= size\n",
    "\n",
    "        # show the result\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5c43edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305804  [    0/60000]\n",
      "loss: 2.290419  [ 6400/60000]\n",
      "loss: 2.277578  [12800/60000]\n",
      "loss: 2.274362  [19200/60000]\n",
      "loss: 2.254799  [25600/60000]\n",
      "loss: 2.233813  [32000/60000]\n",
      "loss: 2.232197  [38400/60000]\n",
      "loss: 2.208999  [44800/60000]\n",
      "loss: 2.199719  [51200/60000]\n",
      "loss: 2.179492  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.7%, Avg loss: 2.169364 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.172896  [    0/60000]\n",
      "loss: 2.166924  [ 6400/60000]\n",
      "loss: 2.117221  [12800/60000]\n",
      "loss: 2.139504  [19200/60000]\n",
      "loss: 2.100432  [25600/60000]\n",
      "loss: 2.031985  [32000/60000]\n",
      "loss: 2.060431  [38400/60000]\n",
      "loss: 1.989859  [44800/60000]\n",
      "loss: 1.984090  [51200/60000]\n",
      "loss: 1.932695  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 1.926222 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.943894  [    0/60000]\n",
      "loss: 1.926046  [ 6400/60000]\n",
      "loss: 1.819224  [12800/60000]\n",
      "loss: 1.867050  [19200/60000]\n",
      "loss: 1.771091  [25600/60000]\n",
      "loss: 1.696237  [32000/60000]\n",
      "loss: 1.722495  [38400/60000]\n",
      "loss: 1.625000  [44800/60000]\n",
      "loss: 1.640464  [51200/60000]\n",
      "loss: 1.541238  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 1.560194 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.612693  [    0/60000]\n",
      "loss: 1.585693  [ 6400/60000]\n",
      "loss: 1.441978  [12800/60000]\n",
      "loss: 1.518746  [19200/60000]\n",
      "loss: 1.404372  [25600/60000]\n",
      "loss: 1.373077  [32000/60000]\n",
      "loss: 1.387032  [38400/60000]\n",
      "loss: 1.312925  [44800/60000]\n",
      "loss: 1.342926  [51200/60000]\n",
      "loss: 1.238515  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.272055 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.342825  [    0/60000]\n",
      "loss: 1.327653  [ 6400/60000]\n",
      "loss: 1.165827  [12800/60000]\n",
      "loss: 1.275907  [19200/60000]\n",
      "loss: 1.156582  [25600/60000]\n",
      "loss: 1.159824  [32000/60000]\n",
      "loss: 1.176961  [38400/60000]\n",
      "loss: 1.117437  [44800/60000]\n",
      "loss: 1.151881  [51200/60000]\n",
      "loss: 1.062490  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 1.092379 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# set the number of epoch (how many times we will use the whole training dataset)\n",
    "epochs = 5\n",
    "\n",
    "# for each of the epoch, we will do train & test.\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    \n",
    "    # do the train!\n",
    "    train_our_model(train_dataloader, our_model, loss_fn, optimizer)\n",
    "    \n",
    "    # do the test!\n",
    "    test_our_model(test_dataloader, our_model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b8cd9",
   "metadata": {},
   "source": [
    "### Predict image labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9856540",
   "metadata": {},
   "source": [
    "Now the model is trained! Let's see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eb289d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f83111dded0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_data[0][0].squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16c0cd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7612, -2.3216, -0.7898, -1.7002, -0.8622,  2.3141, -0.8388,  2.6311,\n",
      "          1.6849,  2.9945]], grad_fn=<AddmmBackward0>)\n",
      "9\n",
      "Ankle boot\n"
     ]
    }
   ],
   "source": [
    "# get the predicted outcome\n",
    "predicted_outcome = our_model(test_data[0][0])\n",
    "print(predicted_outcome)\n",
    "\n",
    "# get the id\n",
    "predicted_id = int(predicted_outcome.argmax())\n",
    "print(predicted_id)\n",
    "\n",
    "# get the label\n",
    "predicted_label = test_data.classes[predicted_id]\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02880086",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8549e2f8",
   "metadata": {},
   "source": [
    "When we will use the model with its trained parameters, we can save it as \"pth\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbc48fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(our_model.state_dict(), \"../data/model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
